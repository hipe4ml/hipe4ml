{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iveMg4lZuOIK"
   },
   "source": [
    "# **Binary classification with hipe4ml**\n",
    "\n",
    "The goal of this tutorial is to provide an example of binary classification with machine learing techniques using the package [hipe4ml](https://hipe4ml.github.io/).\n",
    "\n",
    "This tutorial is based on the measurement of the invariant mass of the $\\mathrm{D^{+}}$ meson, through its three-body decay channel $\\mathrm{D^{+}} \\rightarrow \\mathrm{K^{-}} + \\pi^+ + \\pi^+$, in the transverse-momentum interval $2 \\leq p_{\\mathrm{T}} < 3$ GeV/$c$. The data were collected by ALICE in 2010 and correspond to 240 million minimum-bias pp collisions at $\\sqrt{s}$ = 7 TeV. In this data sample about 4.7 million $\\mathrm{D^{+}}$ candidates have been reconstructed. For training and testing the algorithm, a Monte Carlo simulated data sample with about 4 thousand true $\\mathrm{D^{+}}$ mesons is used.\n",
    "\n",
    "All the data and the MC samples can be found at:\n",
    "\n",
    "- data: https://cernbox.cern.ch/index.php/s/PBtQEyBt9zFJ9Fx\n",
    "- MC (prompt): https://cernbox.cern.ch/index.php/s/98tSXndX0VhUMbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM-yzbqwNqdX"
   },
   "source": [
    "### **Prerequisites**\n",
    "\n",
    "The following packages are needed to follow this tutorial and in general to use _hipe4ml_:\n",
    "\n",
    "- [_uproot_](https://github.com/scikit-hep/uproot) is a reader and a writer of the ROOT file data format and is used to cast blocks of data from the ROOT file as Numpy arrays.\n",
    "\n",
    "- _xxhash_ and _lz4_ are used to decompress the files after download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpdg8u8jBrmH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install hipe4ml\n",
    "!pip install uproot\n",
    "!pip install xxhash\n",
    "!pip install lz4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tF_PTv-FW9TX"
   },
   "source": [
    "### **File download**\n",
    "\n",
    "All the files are downloaded from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnFMalCWBrmu"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -L https://cernbox.cern.ch/index.php/s/PBtQEyBt9zFJ9Fx/download --output data.root\n",
    "!curl -L https://cernbox.cern.ch/index.php/s/98tSXndX0VhUMbi/download --output prompt.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxM-2aDaX7zA"
   },
   "source": [
    "### **Required python packages**\n",
    "\n",
    "The packages required for the tutorial are imported in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1V39gtm4Brm0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hipe4ml.model_handler import ModelHandler\n",
    "from hipe4ml.tree_handler import TreeHandler\n",
    "from hipe4ml.analysis_utils import train_test_generator\n",
    "from hipe4ml import plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kf53-Hp9YSMU"
   },
   "source": [
    "### **Preparing the training set and the test set**\n",
    "\n",
    "All the sets are in _ROOT TTree_ data format and are converted to _pandas dataframe_ format.\n",
    "\n",
    "The _signal_ set is taken from the MC sample and the _background_ set is taken from the data sample, selecting candidates with an invariant mass outside the expected signal region. The mass of $\\mathrm{D^+}$ is 1.87 GeV/$c$: only the candidates with an inavariant mass $m < 1.82$ GeV/$c$ or $1.92< m < 2.0$ GeV/$c$ are selected. The region $m > 2$ GeV/$c$ is excluded to avoid possible contaminations from $\\mathrm{D^{*+}}(2010)$.\n",
    "Only a fraction of the whole data sample (in this example, 3 times the size of the signal set) is used to build the background set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCv484-zBrm5"
   },
   "outputs": [],
   "source": [
    "promptH = TreeHandler('prompt.root','treeMLDplus')\n",
    "dataH = TreeHandler('data.root','treeMLDplus')\n",
    "bkgH = dataH.get_subset('inv_mass < 1.82 or 1.92 < inv_mass < 2.00', size=promptH.get_n_cand()*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZadboiAhjRm"
   },
   "source": [
    "A _total set_ is built by merging the signal and the backgournd sets, the latter after the former. A label is assigned to each candidate of the total set, 0 for background and 1 for signal. The total set is split into a _train set_ and a _test set_, used for training and testing the algorithm, respectively. The fraction of the total set used as test set is defined by the _test_size_ parameter of the function [_sklearn.model_selection.train_test_split_](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CYNdBvjBrm-"
   },
   "outputs": [],
   "source": [
    "train_test_data = train_test_generator([promptH, bkgH], [1,0], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7At73EyQnU8t"
   },
   "source": [
    "The distributions of the features for signal and background are plotted using the function _plot\\_utils_._plot\\_distr_ of _hipe4ml_. Similarly, the correlation matrix for the features is plotted with the function _plt\\_utils_._plot\\_corr_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VrCqOjG9BrnC",
    "outputId": "01d97b07-eba7-4d6d-a1ae-d22841ff2212"
   },
   "outputs": [],
   "source": [
    "vars_to_draw = promptH.get_var_names()\n",
    "\n",
    "leg_labels = ['background', 'signal']\n",
    "\n",
    "plot_utils.plot_distr([bkgH, promptH], vars_to_draw, bins=100, labels=leg_labels, log=True, density=True, figsize=(12, 7), alpha=0.3, grid=False)\n",
    "plt.subplots_adjust(left=0.06, bottom=0.06, right=0.99, top=0.96, hspace=0.55, wspace=0.55)\n",
    "plot_utils.plot_corr([bkgH, promptH], vars_to_draw, leg_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfWmFVp8rYm6"
   },
   "source": [
    "Since we are interested in the measurement of the invariant mass distribution as a function of transverse momentum, both these features are not considered in the training process. Normally, it is also important to remove all the features that are correlated with those of interest, but in this case there are no features singificantly correlated with the invarriant mass or with the transverse momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaLBAbxRBrnH"
   },
   "outputs": [],
   "source": [
    "features_for_train = vars_to_draw.copy()\n",
    "features_for_train.remove('inv_mass')\n",
    "features_for_train.remove('pt_cand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVzd17mSxJRw"
   },
   "source": [
    "### **The model**\n",
    "\n",
    "For this example, [_XGBoost_](https://xgboost.readthedocs.io/en/latest/) is used as classification algorithm. XGBoost is an implementation of gradient boosted decision trees, designed to be highly efficient, flexible and portable.\n",
    "\n",
    "The _hipe4ml_ package deals with the model through the _ModelHandler_ module. The model-handler is used to define the features used in the training process and to set the _hyperparameters_ of the model, such as the number of estimators, the maximum depth of the trees and the learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8bpvHmbBrnL"
   },
   "outputs": [],
   "source": [
    "model_clf = xgb.XGBClassifier()\n",
    "model_hdl = ModelHandler(model_clf, features_for_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fsu0CS_c_N1V"
   },
   "source": [
    "### **Bayesian optimisation of hyperparameters**\n",
    "The optimisation of the hyperparameters is a key step to obtain the best performace from the algorithm. In _hipe4ml_ a Bayesian optimisation is used through the method _ModelHandler.optimize\\_params\\_bayes_.\n",
    "\n",
    "It is an iterative procedure that scan the hyperparameter space in order to find the set of hyperparameters that maximises the performances of the algorithm. The difference between other approaches, like _grid search_ or _random search_, and the Bayesian optimisation is that the latter takes into account past evaluations when choosing the hyperparameter set to evaluate next. This approach reduces the time necessary to find the optimal set of hyperparameters.\n",
    "\n",
    "A set of hyperparameters should be tested on different samples to avoid overfitting problems. Since the number of events is limited, an approach called _cross validation_ is used. It has been proved that the cross validation removes the dependence of the model on the data sample. \n",
    "\n",
    "In the cross validation procedure, the original sample is divided in _n_ parts called _folds_ (in this case 5 folds are used). For each set of hyperparameters, _n-1_ folds are used for the optimisation and the remaining one as test. This operation is repeated after permuting the folds used for optimisation and for testing and the final result is the mean value of all the permutations.\n",
    "\n",
    "The ModelHandler automatically updates the hyperparemeters after their optimisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "n1SkXKkB_Rvv",
    "outputId": "57628e23-ca35-4667-e593-1594d63f558e"
   },
   "outputs": [],
   "source": [
    "hyper_pars_ranges = {'n_estimators': (200, 1000), 'max_depth': (2, 4), 'learning_rate': (0.01, 0.1)}\n",
    "model_hdl.optimize_params_bayes(train_test_data, hyper_pars_ranges, 'roc_auc', nfold=5, init_points=5, n_iter=5, njobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oD4ASKRUBMdO"
   },
   "source": [
    "### **Training and testing the model**\n",
    "The model training is performed with the method _ModelHandler.train\\_test\\_model_. It requires as argument a list containing:\n",
    "1. the training set;\n",
    "2. the real class label for the training set;\n",
    "3. the test set;\n",
    "4. the real class label for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "HcF4BiZjBDNn",
    "outputId": "43665353-4379-4945-f6a7-dd0d946fce9b"
   },
   "outputs": [],
   "source": [
    "model_hdl.train_test_model(train_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8BPKbEvC45k"
   },
   "source": [
    "The predictions for the training and the test sets are obtained with the _predict_ method of the _ModelHandler_ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3DVxwm3RC6RR"
   },
   "outputs": [],
   "source": [
    "y_pred_train = model_hdl.predict(train_test_data[0], False)\n",
    "y_pred_test = model_hdl.predict(train_test_data[2], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQRAtuDeDeZP"
   },
   "source": [
    "The results of the training process can be observed by plotting the distributions of the BDT score for the training and the test sets. This operation is performed with the method _plot\\_utils_._plot\\_output\\_train\\_test_.\n",
    "\n",
    "The distributions of the model scores obtained from the test set are in good agreement with those obtained from the training set. This is a sign that tha model has been treined properly.\n",
    "\n",
    "A disagreement between the distributions obtained from the training set and the datasets would reflect an overfitting by the classification algorithm: the classifier has learnt some characteristics that are peculiar of the training set but that are not true for a general sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "gst09vcjFift",
    "outputId": "9a9e4d83-7859-4669-e515-6dddb87d3c8b"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "\n",
    "ml_out_fig = plot_utils.plot_output_train_test(model_hdl, train_test_data, 100, \n",
    "                                               False, leg_labels, True, density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnEz8j95Jz3n"
   },
   "source": [
    "The quality of the algorithm can be also studied with the ROC curve, that can be plotted with the method _plot\\_utils_._plot\\_roc\\_train\\_test_. A good model classifier is characterised by a large area under the ROC curve (_ROC AUC_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sLLdK40KFlIN",
    "outputId": "1595a77c-8eba-4e6c-f13a-a8a3cf3d8364"
   },
   "outputs": [],
   "source": [
    "roc_train_test_fig = plot_utils.plot_roc_train_test(train_test_data[3], y_pred_test,\n",
    "                                                    train_test_data[1], y_pred_train, None, leg_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWRgkxSlKxg1"
   },
   "source": [
    "### **Apply the model to the data**\n",
    "\n",
    "Once the model has been properly trained, it can be applied to data to separate signal from background events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1cbcQeghLrUl"
   },
   "source": [
    "The result of the model application to a data entry is a BDT score. Data can be selected according to theire BDT score: if it is above a threshold value, the event is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataH.apply_model_handler(model_hdl, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g-o3Qv9LVbA"
   },
   "outputs": [],
   "source": [
    "selected_data_hndl = dataH.get_subset('model_output>0.90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYB1oX7PMFFn"
   },
   "source": [
    "After the application of the model to the data and the consequent selection on the output score, a clear signal is seen, while without any selection it is hidden by the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = [\"after selection\",\"before selection\"]\n",
    "colors_list = ['orangered', 'cornflowerblue']\n",
    "plot_utils.plot_distr([selected_data_hndl, dataH], column='inv_mass', bins=200, labels=labels_list, colors=colors_list, density=True,fill=True, histtype='step', alpha=0.5)\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel(r'm(K$^-\\pi^+\\pi^+$) (GeV/$c^2$)')\n",
    "ax.margins(x=0)\n",
    "ax.xaxis.set_label_coords(0.9, -0.075)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hipe4ml_tutorial_binary.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}